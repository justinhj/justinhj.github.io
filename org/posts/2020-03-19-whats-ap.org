#+TITLE: What's Ap?
#+AUTHOR: Justin Heyes-Jones
#+DATE: 2020
#+STARTUP: showall
#+OPTIONS: toc:nil
#+HTML_HTML5_FANCY:
#+CREATOR: <a href="https://www.gnu.org/software/emacs/">Emacs</a> 26.3 (<a href="http://orgmode.org">Org</a> mode 9.4)
#+BEGIN_EXPORT html
---
layout: post
title: What's Ap?
date: '2020-03-19T00:00:00.000-08:00'
tags: [pure-functional-programming, cats, scala, applicative]
---
#+END_EXPORT
** Applicative Functors
This post is aimed at the Scala programmer who is familiar with the basics of
the language and ideally becoming interested, or already deeply entrenched, in
pure functional programming and curious about ~Applicative Functors~. We'll
delve into the original paper in which they were introduced, converting the
Haskell code to modern Scala, and then look at an efficient implementation of
blending two images using Applicative progamming.
** Functor and Monad
As a Scala programmer you will be no doubt be familar with the ~map~ and
~flatMap~ functions, which you will find in some of the collections and other
data types in the standard Scala library. If you're interested in pure
functional programming, and have used the Cats or Scalaz libraries, you may know
that these two functions are part of the ~Functor~ and ~Monad~ type classes
respectively.

Before looking at ~Apply~ and ~Applicative~ let's review what you can do
Functors and Monads.

Remember, the goal of functional programming is to do most of our work using
pure functions. We use structures like Functors and Monads to manage effects
that are not pure; letting us use pure functions in an effectful world. The
Functor type class gives us the power to take a pure function like ~a => a + 1~
and apply it to the value inside an effect. Here's an example using instances of
the Functor monad for List and Option...

#+BEGIN_SRC scala
List(1,2,3).map(a => a + 1)
// res: List[Int] = List(2, 3, 4)

Option(1).map(a => a + 1)
// res: Option[Int] = Some(2)
#+END_SRC

Whilst Functor gives you the ability to reach inside an effect, apply a pure
function to the value inside there, and wrap it up inside an effect of the same
type. The type signature of map is ~map[A,B](fa: F[A], f: A => B): F[B]~.

Monad instances have two functions. The first, ~pure~ or ~unit~, gives us a way
to lift pure values into an effectful context. ~pure[A](a: A) F[A]~ and you can
think of it as being a type constructor...

#+BEGIN_SRC scala
import cats._
import cats.implicits._

1.pure[List]
// res: List[Int] = List(1)

1.pure[Option]
// res: Option[Int] = Some(1)
#+END_SRC

Pure isn't really giving us something we didn't already have; we could make a
list and an option before. But the pure function is useful as a building block
when building code that uses Monad instances. We'll see it in use later.

Finally, Monad has the ~flatMap~ function. The signature is ~flatMap[A,B](fa:
F[A], f: A => [B]): F[B]~. flatMap comes in handy when we compose two effects
together. It let's you get the result from the first and pass it as a (pure) parameter
to the next. For example, imagine we have two calls that go out over the network
to a database or external service and we use map to chain them together...

#+BEGIN_SRC scala
def getUser(email: String): Future[User] = ???

def getAccountStatus(id: String): Future[AccountStatus] = ???

val accountStatus = getUser("bob@google.com")
  .map(user => getAccountStatus(user.accountId))
// accountStatus has type Future[Future[AccountStatus]]
#+END_SRC

Dealing with nested effects like ~Future[Future[_]]~ creates a burden on us to
reach inside the layers one at a time. If we used flatMap instead it would take
care of flattening the result for us...

#+BEGIN_SRC scala
val accountStatus = getUser("bob@google.com")
  .flatMap(user => getAccountStatus(user.accountId))
// accountStatus has type [Future[AccountStatus]
#+END_SRC

That is the essence of Monad's; being able to compose effects together. Note
that the second call is dependent on the first. It would make no sense to call
~getAccountStatus~ before we called ~getUser~ because we need the user's account
ID. In fact, even if these two effects were completely independent, we would
still have to wait for the first one before calling the second. That's not an
ideal situation because these calls may take tens or even a few hundred
milliseconds. If we want the service to be low latency, we would like to run
these calls concurrently instead of in sequence.
** What's Ap?
Now we're caught up Functors and Monads, let's look at the ~Applicative~
typeclass. It is defined as follows in Cats, with some details removed...

#+BEGIN_SRC scala
trait Applicative[F[_]] extends Apply[F] {
  def pure[A](x: A): F[A]
}
#+END_SRC

If you make an instance of Applicative then you need to supply an implementation
of ~pure~ which is exactly the same as pure found in Monads. You also need to
implement ~Apply~ which looks like this...

#+BEGIN_SRC scala
trait Apply[F[_]] extends Functor[F] {
  def ap[A, B](ff: F[A => B])(fa: F[A]): F[B]
}
#+END_SRC

You can see that ~Apply~ extends Functor which means it has map. Also it has the
function ~ap~ which is, of course, the main subject of this post. What a curious
type signature! Just like with ~map~ we are dealing with an effect type ~F~, and
a parameter ~F[A]~. The difference is the function we want to /apply/ (~ff: F[A
=> B]=~) is also /inside the effect/.

Before talking about what this is useful for, let's look at what it actually
does for various implementations.

*** Applicative instance for Option

#+BEGIN_SRC scala
Option((a:Int) => a + 10).ap(Option(20))
// res: Option[Int] = Some(30)

Option((a:Int) => a + 10).ap(None)
// res: Option[Int] = None

Option.empty[Int => Int].ap(Option(20))
// res: Option[Int] = None

Option.empty[Int => Int].ap(Option.empty[Int])
// res: Option[Int] = None
#+END_SRC

The ap function for Option, then, behaves probably as you'd expect. When you
/apply/ the function, if the ~ff~ argument is ~None~ then there's nothing to
apply and we get the result ~None~. If there is a function in there, we extract
it so that we have a /pure function/ that we can /apply/ to the effectful
argument ~F[A]~. Again, if that is empty we get ~None~, otherwise we get the
value ~f(a)~ which will be wrapped back up in the effect giving ~Some(30)~.

*** Applicative instance for List

#+BEGIN_SRC scala
List((a:Int) => a + 1,
     (a:Int) => a - 10,
     (a:Int) => a + 22).ap(List(1,2,3))
// res: List[Int] = List(2, 3, 4, -9, -8, -7, 23, 24, 25)
#+END_SRC

For ~List~ the input value for ~ff~ has the signature ~List[A => B]~, and each
function in the list is applied to each argument in the input list.

*** Idomaticly apply all the things
All data types that have instances of Applicative have a way to apply a
function wrapped in an effect of that type, and the way that it is applied is
/idomatic/ to that effect. In fact, before the name ~Applicative Functor~ stuck,
they were called ~Idioms~.

You may be scratching your head at this point, for it's not often in programming
that you want to apply a list of functions to a list (although I'm sure you can
probably come up with some ways to use it), and how often do you have functions
in Options? It gets weirder in the case of other data types. With ~Future~, or
~IO~, for example, do you ever remember writing a function that returns a
function from a Future? It's certainly rare. Still more strange would be a
function inside a ~State~ monad, but that is perfectly valid too...

#+BEGIN_SRC scala
import cats.data.State

// Create a function in a State
val fs = State[Int, (Int => Int)]
  (s => (s, (a: Int) => a + s))

// Now to apply it to an appropriate State
val applied = fs.ap(State[Int, Int](s => (s,10)))

// Finally run the Applicative State and grab the value
applied.run(10).value
//res: (Int, Int) = (10, 20)
#+END_SRC

So, everything that has an Applicative can handle pure functions that have been
lifted into effects. In some cases that seems marginally useful and in other
cases seems rather weird. Why is that? I'm going to bury the lede and in the
next section we'll look back to 2008 when Applicative Functors first show up in
academic literature...

** Applicative Programming with Effects

*** Let's Apply ourselves
Applicative Functors first saw light of day in the 2008 paper by McBride and
Patterson, "Applicative Programming with Effects" which you can find here...

[[https://www.staff.city.ac.uk/~ross/papers/Applicative.pdf]]

The paper begins with three motivating examples for the use of Applicative style...

#+BEGIN_QUOTE
This is the story of a pattern that popped up time and again in our daily work,
programming in Haskell (Peyton Jones, 2003), until the temptation to abstract it
became irresistable. Let us illustrate with some examples.
#+END_QUOTE

We'll walk through each of these examples and convert them to use Scala...

**** Sequencing Commands
#+BEGIN_QUOTE
One often wants to execute a sequence of commands and
collect the sequence of their responses, and indeed there is such a function in the
Haskell Prelude (here specialised to IO)
#+END_QUOTE
#+BEGIN_SRC haskell
sequence :: [IO a ] → IO [a ]
sequence [ ] = return [ ]
sequence (c : cs) = do
  x ← c
  xs ← sequence cs
#+END_SRC

Before we get started, if you're following along in your Scala IDE or REPL you
will need some imports listed below. You can also clone the Github repository.

#+BEGIN_SRC scala
import zio._
import zio.console._
import zio.clock._
import zio.duration._
import cats.Applicative
import cats.implicits._
#+END_SRC

... and the following libraries ...

#+BEGIN_SRC scala
libraryDependencies ++= Seq(
 "org.typelevel" %% "cats-core" % "2.1.1",
 "dev.zio" %% "zio" % "1.0.0-RC18")
#+END_SRC

I am using ZIO in place of Haskell's IO Monad, and bringing in Cats to use its
Applicative.

Converting the sequence function from Haskell to Scala...

#+BEGIN_SRC scala
  def monadicSequence[Z,E,A](ios: List[ZIO[Z, E, A]]): ZIO[Z, E, List[A]] = {
    ios match {
      case Nil =>
        zioApplicative.pure(List.empty[A])
      case c :: cs =>
        for (
          x <- c;
          xs <- monadicSequence(cs)
        ) yield (x +: xs)
    }
  }
#+END_SRC

If you're not familiar with ~ZIO~ you can think of it as a replacement for the standard library
Scala ~Future~, but it has better performance and a lot more features. It is
also not eagerly evaluated like Future. To explain, when you create a future it runs
immediately and you cannot run it again. You can create a ZIO and run it when
you decide to and as many times as you want.

To demonstrate this sequence running let's write an implementation of a silly
algorithm called Sleep Sort. Sleep Sort works by waiting an amount of time based
on the value of the number. Emitting the numbers in this way sorts them
(assuming your scheduler is accurate enough). Let's be clear, this is a stupid
way to sort numbers, but it's handy as a way to illustrate our ~monadicSequence~
function.

#+BEGIN_SRC scala
def delayedPrintNumber(s: Int): ZIO[Console with Clock,String,Int] = {
    putStrLn(s"Preparing to say number in $s seconds") *>
    putStrLn(s"$s").delay(s.seconds) *>
    ZIO.succeed(s)
}
val ios1 = List(6,5,2,1,3,8,4,7).map(delayedPrintNumber)
// ios1: List[ZIO[Console with Clock,String,Int]]
#+END_SRC

The function creates an IO effect, which when run will immediately print a
message and then wait ~s~ seconds before printing the number. We map the
function across a list of numbers to generate a list of IO effects, which we can
then run.

You may be surprised that this does not work. Instead of running all the effects
at once and printing them out in order it just executes the first IO (wait 6
seconds), then the second (wait 5 seconds).

#+BEGIN_SRC
Monadic version

Preparing to say number in 6 seconds
6
Preparing to say number in 5 seconds
5
// ... and so on for a while
#+END_SRC

If you were not surprised maybe you're ahead of me, and know that our
~monadicSequence~ function cannot possibly run all the effects at once by virtue
of it being monadic in the first place.

That ~for~ comprehension is really hiding that we are calling flatMap on each
successive IO, and flatMap sequences things together. You must wait for the
result of the first effect before you can evaluate the second. So whilst the
first implementation of ~sequence~ in the paper will absolutely work, it will
not let us implement our sleep sort, nor let us parallelize the IO's in general.

Anyway let's get back to the paper, at this point the authors observe...

#+BEGIN_QUOTE
In the (c : cs) case, we collect the values of some effectful computations, which we
then use as the arguments to a pure function (:). We could avoid the need for names
to wire these values through to their point of usage if we had a kind of ‘effectful
application’.
#+END_QUOTE

By effectful application they are talking about the ~ap~ function, and they go
on to say that it lives in the Haskell Monad library. Given that function they
rewrite the ~sequence~ function as follows...

#+BEGIN_SRC haskell
sequence :: [IO a ] → IO [a ]
sequence [ ] = return [ ]
sequence (c : cs) = return (:) ‘ap‘ c ‘ap‘ sequence cs
#+END_SRC

#+BEGIN_QUOTE
Except for the noise of the returns and aps, this definition is in a fairly standard
applicative style, even though effects are present.
#+END_QUOTE

Note that the ~ap~ they are using here is in the Monad library, and implemented
using flatMap, so it will not yet allow our sleep sort to work. However, I've
implemented an Applicative instance for ZIO which does not have that
limitation...

#+BEGIN_SRC scala
implicit def zioApplicative[Z,E] = new Applicative[ZIO[Z,E,?]] {
    def pure[A](x: A) = ZIO.succeed(x)
    def ap[A, B](ff: ZIO[Z,E,A => B])(fa: ZIO[Z,E,A]) = {
      map2(ff, fa){
        (f,a) =>
          f(a)
      }
    }
    override def map2[A, B, C](fa: ZIO[Z,E,A], fb: ZIO[Z,E,B])(f: (A, B) => C) :
      ZIO[Z,E,C] = {
        fa.zipPar(fb).map{case (a,b) => f(a,b)}
    }
  }
#+END_SRC

It's not important to understand all the details here, all you need understand
is we now have an ~ap~ that we can apply to ZIO effects that is truly parallel,
so if you're not interested then skip to the next paragraph.

#+BEGIN_aside
The ~pure~ function is straightforward, it just wraps a pure value in a
succeeded ZIO. The ~ap~ function is more interesting. Whilst it's not obvious
how you would implemented ap in for ZIO, it is really easy to implement ~map2~.
~map2~ comes in handy because it lets you take the results of two effects and
pass them to a pure function. The function has the signature ~f: (A, B) => C~.
We use the ZIO function ~zipPar~ to execute the two effects _in parallel_, and
if both ~fa~ and ~fb~ yield values then they are mapped with the pure function
giving us a ZIO with the final result inside. Happily, you can implement ap in
terms of map2, so that solves our problem.
#+END_aside

Here's the conversion of the applicative version of ~sequence~ to Scala...

#+BEGIN_SRC scala
def applicativeSequence[Z,E,A](ios: List[ZIO[Z, E, A]]): ZIO[Z, E, List[A]] = {
    ios match {
      case Nil =>
        ZIO.succeed(List.empty[A])
      case c :: cs =>
        val ff: ZIO[Z,E, A => (List[A] => List[A])] =
          zioApplicative.pure(((a: A) => (listA: List[A]) => a +: listA))
        val p1 = ff.ap(c)
        p1.ap(applicativeSequence(cs))
    }
  }
#+END_SRC

It's a little bit noisier than the Haskell code, but most of that is having to
be more verbose about the types to keep the type checker happy. In fact the
parts of each implementation match up together.

Now we can run that and you will see that the effects are now parellelised and
our sleep sort works!

#+BEGIN_SRC
Applicative version

Preparing to say number in 6 seconds
Preparing to say number in 2 seconds
Preparing to say number in 1 seconds
Preparing to say number in 3 seconds
Preparing to say number in 8 seconds
Preparing to say number in 4 seconds
Preparing to say number in 7 seconds
Preparing to say number in 5 seconds
1
2
3
4
5
6
7
8
#+END_SRC

Note that the point the authors were making here was just to show that the
~sequence~ function is a pattern that came up often, that could be more
succinctly expressed with ~ap~. Showing that it also enables our effects to run
in parallel, given the correct implementation, was just to show one of the
benefits of avoiding Monad when effects are not dependent on each other.

**** Matrix Transposition
The second example in the paper is that of Matrix transposition, which takes a
matrix and flips it along a diagonal. For example...

#+BEGIN_SRC
Original matrix
 1  2  3  4  5
 6  7  8  9 10
11 12 13 14 15

Transposed matrix
 1  6 11
 2  7 12
 3  8 13
 4  9 14
 5 10 15
#+END_SRC

In Haskell, we first see this implememtation of transpose...

#+BEGIN_SRC haskell
transpose :: [[a ]] → [[a ]]
transpose [ ] = repeat [ ]
transpose (xs : xss) = zipWith (:) xs (transpose xss)

repeat :: a → [a ]
repeat x = x : repeat x
#+END_SRC

Let's translate this to Scala. The algorithm works by taking each row in turn
and /zipping/ it with each subsequent row.

First we need to be careful about the function ~repeat~ which returns an
infinite number of whatever x is. This is used in the transpose for the last row
of the matrix where we want a number of empty lists to finish our recursion but
we don't know how many, so we want to just keep taking them. Since Haskell is by
default lazily evaluated this will work fine. In Scala as soon as we evaluate
repeat we will run into an infinite loop. That's easily fixed by switching to
~LazyList~ which is part of the standard library. (Before Scala 2.13 it was
called Stream).

#+BEGIN_SRC scala
def repeat[A](a: A): LazyList[A] = a #:: repeat(a)
#+END_SRC

The function ~zipWith~ has the following type signature...

#+BEGIN_SRC haskell
zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
#+END_SRC

In other words it takes two lists and a pure function of two arguments, and
creates a new list by applying the function to each element. It will stop once
it runs out of elements in one of the lists. Here's the Scala version.

#+BEGIN_SRC scala
def zipWith[A, B, C](as: LazyList[A], bs: LazyList[B])(
      f: (A, B) => C): LazyList[C] = {
    as.zip(bs).map { case (a, b) => f(a, b) }
  }
#+END_SRC

With the pieces in place I can now implement the transpose as follows...

#+BEGIN_SRC scala
def transpose[A](matrix: LazyList[LazyList[A]]): LazyList[LazyList[A]] = {
  matrix match {
    case LazyList() => repeat(LazyList.empty)
    case xs #:: xss =>
      zipWith(xs, transpose(xss)) {
        case (a, as) =>
          a +: as
      }
  }
}
#+END_SRC

The next step in the paper is to make this look a bit more /applicative/ by
using a combination of ~repeat~ and ~zapp~...

#+BEGIN_SRC haskell
zapp :: [a → b ] → [a ] → [b ]
zapp (f : fs) (x : xs) = f x : zapp fs xs
zapp = [ ]

transpose :: [[a ]] → [[a ]]
transpose [ ] = repeat [ ]
transpose (xs : xss) = repeat (:) ‘zapp‘ xs ‘zapp‘ transpose xss
#+END_SRC

#+BEGIN_QUOTE
Except for the noise of the repeats and zapps, this definition is in a fairly standard
applicative style, even though we are working with vectors.
#+END_QUOTE

**** Evaluating Expressions
The third example of applicative style is an expression evaluator that can add
numbers, both literals and numbers bound to strings and stored in an environment.

#+BEGIN_QUOTE
When implementing an evaluator for a language of expressions, it is customary to
pass around an environment, giving values to the free variables.
#+END_QUOTE

The Haskell code looks like this...

#+BEGIN_SRC haskell
data Exp v = Var v
  | Val Int
  | Add (Exp v) (Exp v)

eval :: Exp v → Env v → Int
eval (Var x ) γ = fetch x γ
eval (Val i) γ = i
eval (Add p q) γ = eval p γ + eval q γ
#+END_SRC

Converting to Scala is straightforward...

#+BEGIN_SRC scala
sealed trait Exp
case class Val(value: Int) extends Exp
case class Add(left: Exp, right: Exp) extends Exp
case class Var(key: String) extends Exp

case class Env[K](kv: Map[K,Int])

def fetch(key: String)(env: Env[String]) : Int =
  env.kv.getOrElse(key, 0)

def eval(exp: Exp, env: Env[String]) : Int = {
  exp match {
    case Val(value) => value
    case Var(key) => fetch(key)(env)
    case Add(left, right) =>
      eval(left, env) + eval(right, env)
  }
}
#+END_SRC

Here I've made the environment a simple key value store, and, to avoid
complicating the example with error handling, if a variable is not present in
the environment I just default to returning zero.

Following the pattern of the previous two examples, the authors then pull some
magic to make the applicative pattern more noticable...

#+BEGIN_QUOTE
We can eliminate the clutter of the explicitly threaded environment with a little
help from some very old friends, designed for this purpose
#+END_QUOTE

#+BEGIN_SRC haskell
eval :: Exp v → Env v → Int
eval (Var x ) = fetch x
eval (Val i) = K i
eval (Add p q) = K (+) ‘S‘ eval p ‘S‘ eval q

where
K :: a → env → a
K x γ = x

S :: (env → a → b) → (env → a) → (env → b)
S ef es γ = (ef γ) (es γ)
#+END_SRC

So this all looks a bit cryptic. Who are the old friends? Well, if you look at
the type signature of ~K~ it is actually the ~pure~ function, and ~S~
is the ~ap~ function. This is in fact what we'd call the ~Reader~ Monad in
Scala.

By old friends, the authors are referring to the [[https://en.wikipedia.org/wiki/SKI_combinator_calculus][SKI Combinator Calculus]].

Let's reimplement in Scala using the ~Reader~.

#+BEGIN_SRC scala
def fetchR(key: String) = Reader[Map[String,Int], Int](env => env.getOrElse(key, 0))
def pureR(value: Int) = Reader[Map[String,Int], Int](env => value)

def evalR(exp: Exp): Reader[Map[String,Int], Int] = {
  exp match {
    case Val(value) => pureR(value)
    case Var(key) => fetchR(key)
    case Add(left, right) =>
      val f = Reader((env:Map[String,Int]) =>
        (a:Int) => (b:Int) => a + b)
      val leftEval = evalR(left).ap(f)
      evalR(right).ap(leftEval)
  }
}
#+END_SRC

And take it for a test drive...

#+BEGIN_SRC scala
val env1 = Env(Map("x" -> 3, "y" -> 10))
val exp1 = Add(Val(10), Add(Var("x"), Var("y")))

println(s"Eval : ${eval(exp1, env1)}")
// Eval : 23
#+END_SRC

*** The Applicative Type class
To summarize, we've seen three different effects used in applicative style; IO
(or ZIO), List and Reader. Now you can see why it makes sense to be able to
apply a function that is wrapped in these effects. What we needed, and got with
~ap~, is a way to lift a pure function so we can apply it to a chain of effects
of the same effect type.

Next in the paper the authors describe the laws which an instance of the
Applicative type class must adhere to, which is out of scope for this post but
is put succinctly in English as follows...

#+BEGIN_QUOTE
The idea is that pure embeds pure computations into the pure fragment of an
effectful world—the resulting computations may thus be shunted around freely, as
long as the order of the genuinely effectful computations is preserved.
#+END_QUOTE

For more detail on the applicative laws check out chapter 12, section 5 of [[https://livebook.manning.com/book/functional-programming-in-scala/chapter-12/80][The Red Book]]

Next we are show that /Applicatives are all Functors/ (hence the name
Applicative Functors), because you can implement the map operation as follows...

#+BEGIN_SRC scala
// Declare map in terms of pure and ap
def map[A,B,F[_]: Applicative](fa: F[A], f: A => B): F[B] = {
  Applicative[F].pure(f).ap(fa)
}

// Map a function over a list
map(List(1,2,3,4,5), (a:Int) => a + 1)
// res: List[Int] = List(2, 3, 4, 5, 6)
#+END_SRC

Note that you don't have to do this with Cats instances because all
Applicatives have their Functor instance taken care of too.

The paper then notes that all uses of Applicatives follow this pattern of
lifting a pure function and applying it to a chain of effects, and suggests a
new syntax for shifting into the /Idiom/ of the applicative functor. The syntax
is a special pair of brackets...

#+BEGIN_SRC haskell
[[ ff f1 f2 f3 ... fn ]]
#+END_SRC

Although this has not been widely adopted in either Haskell or Scala as far as I
can tell, you can try it yourself using this delightfully named (and
implemented) Scala library: [[https://github.com/sammthomson/IdiomEars][Idiom Ears]]. This will let you closely match the
syntax from the paper; for example...

#+BEGIN_SRC scala
val f = (a: Int) => (b: Int) => a * b
⊏| (f) (List(1, 2)) (List(3, 4)) |⊐
// List(3, 4, 6, 8)

// Which is equivalent to
Applicative[List].pure(f).ap(List(1,2)).ap(List(3,4))
#+END_SRC

If you do fall in love with the idiom brackets of McBride and Patterson then
knock yourself out, but you may have to invest some time bringing the project
back to life as it has suffered some bitrot since 2016. There is a demo of
IdiomEars in the Github repository accompanying this post, but I simply copied
the code into my project rather than spend time updating it.

*** Moving right along to Traverse
#+BEGIN_QUOTE
Have you noticed that sequence and transpose now look rather alike? The details
that distinguish the two programs are inferred by the compiler from their types.
Both are instances of the applicative distributor for lists.
#+END_QUOTE

At this point in the paper we have seen the birth of the Applicative type class
which encapsulates the ~ap~ and ~pure~ functions needed to implement the
patterns above. Next the authors describe another new type class, ~Traverse~,
which lets us generalize the pattern further...

#+BEGIN_SRC haskell
dist :: Applicative f ⇒ [f a ] → f [a ]
dist [ ] = ⊏| [ ] |⊐
dist (v : vs) = ⊏| (:) v (dist vs) |⊐
#+END_SRC

Note that I'm using the unicode from Idiom Ears to replace the fancy brackets
from the paper which I cannot reproduce here, but you get the idea. Let's
rewrite in Scala...

#+BEGIN_SRC scala
// applicative distributor for lists
def dist[A, F[_]](fs: List[F[A]])(implicit app: Applicative[F]): F[List[A]] = {
  fs match {
    case Nil =>
      app.pure(List.empty[A])
    case c :: cs =>
      val w1 = app.pure((a: A) => (listA: List[A]) => a +: listA)
      val w2 = w1.ap(c)
      w2.ap(dist(cs))
  }
}

// dist a list of options
println(dist(List(Option(10), Option(10), Option(3), Option(4))))
// Some(List(10, 10, 3, 4))

// Note that we have short circuiting
println(dist(List(None, Option(10), Option(3), Option(4))))
// None
#+END_SRC

Note that this short-circuits. We fail as soon as a single ~None~ shows up. Why?
It's because although applicative allows us to avoid the enforced sequencing of
Monad's flatMap, many types have instances of ~ap~ implemented in terms of
flatMap anyway, because that matches the expectation of users for that type.

We could override the Cats instance for Option with our own. What we do instead
is create Applicative versions of type classes. For example, our monadic friend
Either (which represents an error or a success value) has an applicative
alter-ego ~Validated~. Rather than short-circuit on failure, Validated allows us
to acculate errors so we can provide valuable feeback ot the caller. That is one
of the super-powers of Applicatives!

#+BEGIN_SRC scala
val someValidateds: List[Validated[NonEmptyList[String],Int]] =
  (List("Had some error".invalidNel, 10.valid, "Another error".invalidNel, 4.valid))

// Try the same with Validated that has an Applicative instance
println("Validated failure example: " + dist(someValidateds))
// Validated failure example: Invalid(NonEmptyList(Had some error, Another error))
#+END_SRC

Just by changing data types we have completely changed the behaviour from
short-circuiting to being able to //accumulate the errors/. Just imagine that these
are expensive computations or slow network calls, and you can see how avoiding
sequencing can really save us in computing costs, and thereby save us money.
Furthermore we can improve user experience. We can validate a whole form from
the user at once and send all the corrections needed rather than necessitate a
painful back and forth until the whole form is valid.

Anyway enough real world talk let's get back to ~dist~.

#+BEGIN_QUOTE
Distribution is often used together with ‘map’.
#+END_QUOTE

Fair enough. The ~dist~ function we developed above would be enhanced in
usefullness if it could map a list of pure values into some effect type first.
Let's take a look at a poor way to implement that...

#+BEGIN_SRC haskell
flakyMap :: (a → Maybe b) → [a ] → Maybe [b ]
flakyMap f ss = dist (fmap f ss)
#+END_SRC

We can translate pretty much directly to Scala...

#+BEGIN_SRC scala
def flakyMap[A,B](f: A => Option[B], as: List[A]): Option[List[B]] = {
  dist(as.map(f))
}

println("Flakymap success: " + flakyMap((n: Int) => Option(n * 2), List(1,2,3)))
// Flakymap success: Some(List(2, 4, 6))
println("Flakymap failure: " + flakyMap((n: Int) => if(n%2==1) Some(n) else None, List(1,2,3)))
// Flakymap failure: None
#+END_SRC

That's clearly useful, and it works, but it's flaky because we have to process
the list twice. First we map over the list to transform it, then we do it again
with the dist function. How about we do both at once? That's ~Traverse~...

#+BEGIN_SRC haskell
traverse :: Applicative f ⇒ (a → f b) → [a ] → f [b ]
traverse f [ ] = ⊏| [ ] |⊐
traverse f (x : xs) = ⊏| (:) (f x ) (traverse f xs) |⊐
#+END_SRC

And a Scala version...

#+BEGIN_SRC scala
def listTraverse[A, B, F[_]](f: A => F[B], fs: List[A])
     (implicit app: Applicative[F]): F[List[B]] = {
  fs match {
    case Nil =>
      app.pure(List.empty[B])
    case c :: cs =>
      val w1 = app.pure((b: B) => (listB: List[B]) => b +: listB)
      val w2 = w1.ap(f(c))
      w2.ap(listTraverse(f, cs))
  }
}
// Output is the same as flakyMap
#+END_SRC

By providing the identity function for ~f~ we get the ~sequence~ function back
in terms of traverse...

#+BEGIN_SRC scala
def sequence[A, F[_]](fs: List[F[A]])
    (implicit app: Applicative[F]): F[List[A]] = {
  listTraverse((fa: F[A]) => fa, fs)
}
#+END_SRC

Finally we get to the Traverse type class, which gives us an interface to write
traverse for two effect types rather than just List and another effect. We have
two functions, traverse and dist, which are represented in Scala today as
traverse and sequence.

#+BEGIN_SRC haskell
class Traversable t where
traverse :: Applicative f ⇒ (a → f b) → t a → f (t b)
dist :: Applicative f ⇒ t (f a) → f (t a)
dist = traverse id
#+END_SRC

There's no need to show the Scala because we can reply on the implementations in
the Cats library, but the instance implementations for list are as above. In the
paper we see that you can also traverse more complex structures such as a
tree...

#+BEGIN_SRC scala
sealed trait Tree[+A]
case object Leaf extends Tree[Nothing]
case class Node[A](left: Tree[A], a: A, right: Tree[A]) extends Tree[A]

def treeTraverse[A, B, F[_]](f: A => F[B], fs: Tree[A])
                (implicit app: Applicative[F]): F[Tree[B]] = {
  fs match {
    case Leaf =>
      app.pure(Leaf)
    case Node(left, a, right) =>
      val w1 = app.pure((l: Tree[B]) =>
        (v: B) =>
        (r: Tree[B]) => Node(l,v,r))
      val w2 = w1.ap(treeTraverse(f,left))
      val w3 = w2.ap(f(a))
      w3.ap(treeTraverse(f,right))
  }
}

val tree1 = Node(Leaf, 10, Node(Leaf, 5, Node(Leaf, 10, Leaf)))
println("treeTraverse: " + treeTraverse((n: Int) => Option(n + 1), tree1))
// treeTraverse: Some(Node(Leaf,11,Node(Leaf,6,Node(Leaf,11,Leaf))))
#+END_SRC

Note that in your own code you would usually lean on the Traverse type class and
override some methods to provide your own implementations.

Another thing to highlight the expressive power of traverse is that we can use
it to do a ~map~ just like a ~~Functor~ by using the Id (identity) Monad as our
effect type. The Id monad simply wraps a pure value and has no other effect, so
we can use it to use traverse as a functor as follows...

#+BEGIN_SRC scala
@ List[Int](1,2,3).traverse((a: Int) => (1 + a): Id[Int])
// Id[List[Int]] = List(2, 3, 4)
#+END_SRC

*** Monoids are phantom Applicative functors
This section of the paper, part four if you are reading along, has an intriguing
title. Whilst short, there is a lot of information in a small space on how we
can use Monoids, Applicatives and Traverse to do some cool things. I will go
much slower than the paper as some of the concepts take some time to get your
head around.

Monoids are a type class that provides an interface to join things together such
as appending strings or adding numbers. In addition they give us a way to
represent a zero value for the data type, which will be useful in a moment. If
you want to dig into Monoids in more detail I have written a couple of posts on
the subject...

[[http://justinhj.github.io/2019/06/10/monoids-for-production.html][Monoids for Production [2019]​]]
[[https://medium.com/yoppworks-reactive-systems/persistent-entities-with-monoids-a44212a157fb][Persistent Entities with Monoids [2020]​]]

**** Every Applicative is a Monoid
It's possible to implement a Monoid instance that works for any Applicative. In
Scala it looks like this...

#+BEGIN_SRC scala
implicit def appMonoid[A: Monoid, F[_]: Applicative] = new Monoid[F[A]] {
  def empty: F[A] = Applicative[F].pure((Monoid[A].empty))
  def combine(x: F[A], y: F[A]): F[A] =
    Applicative[F].map2(x,y)(Monoid[A].combine)
}
#+END_SRC

What does this give us? We can join Applicative Effects togther, and when we do
so they are joined in the =idiom= of the effect type. So for example when
combining a list with its default Monoid instance it will simply append the
lists like this...

#+BEGIN_SRC scala
List(1,2,3) |+| List(4,5,6)
// res: List[Int] = List(1, 2, 3, 4, 5, 6)
#+END_SRC

But if instead we bring into scope a monoid for List we get the applicative
application instead...

#+BEGIN_SRC scala
implicit val m = appMonoid[Int, List]
List(1,2,3) |+| List(4,5,6)
// res: List[Int] = List(5, 6, 7, 6, 7, 8, 7, 8, 9)
#+END_SRC

**** Every Monoid is an Applicative?
It does not work the other way around, but some types with Monoid instances can
use those instances in their Applicative implementation. For example =Tuple2= in
the Cats library does just that. The actual implementation is split into two
because of the way the Cats class hierarchy is organized, so here's a simplified
version so you can see what's going on...

#+BEGIN_SRC scala
implicit def appTuple2[X: Monoid] = new Applicative[Tuple2[X,?]] {
  def pure[A](a: A): (X, A) = (Monoid[X].empty, a)

  def ap[A, B](ff: (X, A => B))(fa: (X, A)): (X, B) = {
    (ff._1.combine(fa._1),
     ff._2(fa._2))
  }
}
#+END_SRC






**** Const

#+BEGIN_SRC haskell
newtype Accy o a = Acc{acc :: o }
#+END_SRC

In Scala this is...

#+BEGIN_SRC scala
def const[A, B](a: A)(b: => B): A = a
#+END_SRC

Const, or Accy, is a strange looking data type that takes two type parameters,
and in fact takes two values, but we can only every recover the first. This is
why the second parameter is called a ~phantom~.

We can create a Const with any crazy type we want for the ~B~ parameter...

#+BEGIN_SRC scala
@ Const[Int, com.oracle.webservices.internal.api.message.MessageContext](12).getConst
res10: Int = 12
#+END_SRC

So what use is Const? If you create an Applicative Functor for Const

#+BEGIN_SRC haskell
instance Monoid o ⇒ Applicative (Accy o) where
pure = Acc ∅
Acc o1 ~ Acc o2 = Acc (o1 ⊕ o2)
#+END_SRC

